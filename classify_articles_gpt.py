"""Second-layer GPT classifier.

This module runs after ``filter_relevance_gpt.py``. It assigns a
human-readable category and region label to each article. The results
are stored for later summarization.
"""

import json
import os
import re
import asyncio
import google.generativeai as genai
from dotenv import load_dotenv
from typing import Dict, List, Any

INPUT_FILE = "data/classified_articles.json"
OUTPUT_ALL_FILE = "data/news_data.json"
CATEGORY_DIR = "data/categorized"

load_dotenv()
genai.configure(api_key=os.getenv("GEMINI_API_KEY"))
model = genai.GenerativeModel("gemini-2.5-flash")

CATEGORY_MAPPING = {
    "Research": "Research",
    "Infrastructure": "Infrastructure",
    "FinTech": "FinTech",
    "Startup": "Startup",
}

STANDARD_CATEGORIES = list(set(CATEGORY_MAPPING.values()))


REGIONS = ["Global", "Taiwan"]

MAX_CONTENT_TOKENS = 1000  # Adjust based on your model's token limit


def truncate_text(text: str, max_tokens: int = MAX_CONTENT_TOKENS) -> str:
    """æˆªæ–·æ–‡æœ¬åˆ°æŒ‡å®šçš„æœ€å¤§ token æ•¸ï¼Œé¿å…è¶…å‡ºæ¨¡å‹é™åˆ¶ã€‚"""
    words = text.split()
    return " ".join(words[:max_tokens])

def load_prompt(path: str) -> str:
    """å¾æª”æ¡ˆè¼‰å…¥ Prompt æ¨¡æ¿ã€‚"""
    with open(path, "r", encoding="utf-8") as f:
        return f.read()

VERSION = "v2.1"
PROMPT_PATH = f"prompts/classify_articles_{VERSION}.txt" # ç¢ºä¿é€™å€‹è·¯å¾‘æŒ‡å‘ä½ çš„æ–° Prompt æª”æ¡ˆ
PROMPT_TEMPLATE = load_prompt(PROMPT_PATH)


def load_articles(path: str) -> List[Dict[str, Any]]:
    """è¼‰å…¥å¾…åˆ†é¡çš„æ–‡ç« åˆ—è¡¨ã€‚"""
    if not os.path.exists(path):
        return []
    with open(path, "r", encoding="utf-8") as f:
        try:
            return json.load(f)
        except json.JSONDecodeError:
            raise RuntimeError(f"Invalid JSON in {path}")


semaphore = asyncio.Semaphore(3) # é™åˆ¶ä½µç™¼è«‹æ±‚æ•¸é‡ï¼Œé¿å… API é€Ÿç‡é™åˆ¶


def _parse_response(text: str) -> Dict[str, Any]:
    """è§£ææ¨¡å‹çš„å›æ‡‰æ–‡æœ¬ï¼Œæå–é¡åˆ¥å’Œåœ°å€è³‡è¨Šã€‚"""
    raw_text = text
    try:
        # å˜—è©¦æ‰¾åˆ° JSON ç‰©ä»¶ï¼Œé€šå¸¸æ¨¡å‹æœƒå°‡ JSON åŒ…è£¹åœ¨ ```json ... ``` ä¸­
        match = re.search(r"\{[^{}]*\}", raw_text, re.DOTALL)
        if match:
            raw_text = match.group(0)
        else:
            # å¦‚æœæ²’æœ‰æ‰¾åˆ° JSON åŒ…è£¹ï¼Œå‰‡å˜—è©¦ç§»é™¤å¸¸è¦‹çš„ Markdown æ¨™è¨˜
            raw_text = raw_text.replace("```json", "").replace("```", "").strip()

        data = json.loads(raw_text)
        # æ¨¡å‹æ‡‰è¿”å› "category" å’Œ "region"
        return {
            "category": data.get("category", ""),
            "region": data.get("region", "Global"),
            "keep": data.get("keep", False) # å¾æ¨¡å‹å›æ‡‰ä¸­ç²å– keep å±¬æ€§
        }
    except Exception as e:
        print("âš ï¸ ç„¡æ³•è§£ææ¨¡å‹å›æ‡‰:", e)
        print("ğŸ§ª åŸå§‹å›æ‡‰æ–‡æœ¬ç‚º:", repr(raw_text))
        # è¿”å›é è¨­å€¼ï¼Œç¢ºä¿ç¨‹å¼ä¸æœƒå´©æ½°
        return {"category": "", "region": "Global", "keep": False}


async def classify_article(article: Dict[str, Any]) -> Dict[str, Any] | None:
    """å°å–®ç¯‡æ–‡ç« é€²è¡Œåˆ†é¡ã€‚"""
    title = article.get("title", "")
    content = article.get("content") or article.get("description", "")
    if not title or not content:
        return None # å¦‚æœæ²’æœ‰æ¨™é¡Œæˆ–å…§å®¹å‰‡è·³é

    short_content = truncate_text(content)
    # å°‡æ–‡ç« æ¨™é¡Œå’Œæˆªæ–·å¾Œçš„å…§å®¹çµ„åˆæˆ Prompt
    prompt = f"{PROMPT_TEMPLATE.strip()}\n\nTitle: {title}\n\n Content:\n{short_content}"

    async with semaphore: # ä½¿ç”¨ semaphore é™åˆ¶ä½µç™¼è«‹æ±‚
        try:
            # ç•°æ­¥å‘¼å«æ¨¡å‹é€²è¡Œå…§å®¹ç”Ÿæˆ
            resp = await model.generate_content_async(prompt)
            text = resp.text
            print("ğŸ“© æ¨¡å‹åŸå§‹å›æ‡‰:", text)
            return _parse_response(text)
        except Exception as e:
            print(f"âŒ è«‹æ±‚æœŸé–“ç™¼ç”Ÿä¾‹å¤–: {e}")
            return None # ç™¼ç”ŸéŒ¯èª¤æ™‚è¿”å› None


async def main_async() -> None:
    """ä¸»ç•°æ­¥å‡½æ•¸ï¼Œè² è²¬è¼‰å…¥ã€åˆ†é¡ã€å„²å­˜æ–‡ç« ã€‚"""
    articles = load_articles(INPUT_FILE)
    os.makedirs(CATEGORY_DIR, exist_ok=True)

    # åˆå§‹åŒ–åˆ†çµ„å­—å…¸ï¼Œä½¿ç”¨ STANDARD_CATEGORIES
    grouped = {region: {cat: [] for cat in STANDARD_CATEGORIES} for region in REGIONS}
    results: List[Dict[str, Any]] = [] # å„²å­˜æ‰€æœ‰åˆ†é¡å¾Œçš„æ–‡ç« 

    valid_articles: List[Dict[str, Any]] = []
    for art in articles:
        title = art.get("title", "")
        content = art.get("content") or art.get("description", "")
        if not title or not content:
            continue
        valid_articles.append(art)

    # ä½µç™¼åŸ·è¡Œæ‰€æœ‰æ–‡ç« çš„åˆ†é¡ä»»å‹™
    tasks = [classify_article(art) for art in valid_articles]
    responses = await asyncio.gather(*tasks)

    # å®šç¾©ä½ èªç‚ºæ˜¯ AI ç›¸é—œçš„é¡åˆ¥åˆ—è¡¨
    AI_RELATED_CATEGORIES = ["Research", "Infrastructure", "FinTech", "Startup"]
    # é€™è£¡çš„åˆ—è¡¨éœ€è¦æ ¹æ“šä½ å°ã€ŒAIç›¸é—œã€çš„å…·é«”å®šç¾©ä¾†èª¿æ•´
    # å¦‚æœä½ èªç‚ºæ‰€æœ‰é€™å››å€‹é¡åˆ¥éƒ½å¯èƒ½åŒ…å«AIï¼Œé‚£å°±ä¿ç•™ï¼Œå¦å‰‡å¯ä»¥æ›´å…·é«”
    # ä¾‹å¦‚ï¼Œå¦‚æœåªæœ‰ Research å’Œ Infrastructure çš„ AI éƒ¨åˆ†ä½ æ„Ÿèˆˆè¶£ï¼Œé‚£å°±èª¿æ•´

    for art, result in zip(valid_articles, responses):
        if not result:
            continue

        raw_category_from_model = result.get("category", "")
        region = result.get("region", "Global")
        keep = result.get("keep", False)

        standardized_category = CATEGORY_MAPPING.get(raw_category_from_model, "Unknown")

        art["category"] = standardized_category
        art["region"] = region
        art["keep"] = keep

        # æ–°å¢çš„ AI ç›¸é—œç¯©é¸é‚è¼¯
        # åªæœ‰ç•¶ keep ç‚º True ä¸” category å±¬æ–¼ AI_RELATED_CATEGORIES æ™‚æ‰ä¿ç•™
        if keep and standardized_category in AI_RELATED_CATEGORIES:
            results.append(art)
            if region in grouped and standardized_category in grouped[region]:
                grouped[region][standardized_category].append(art)
            else:
                print(f"Warning: Article with category '{standardized_category}' or region '{region}' not added to grouped dictionary.")
        else:
            # å¦‚æœæ–‡ç« ä¸ä¿ç•™ï¼ˆkeep=falseï¼‰æˆ–è€…ä¸å±¬æ–¼ AI ç›¸é—œé¡åˆ¥ï¼Œéƒ½å°‡å…¶æ’é™¤
            if not keep:
                print(f"æ–‡ç«  '{art.get('title', 'ç„¡æ¨™é¡Œ')}' å›  keep=false è€Œè¢«æ‹’çµ•ã€‚")
            else: # é€™è¡¨ç¤º keep æ˜¯ trueï¼Œä½† category ä¸åœ¨ AI_RELATED_CATEGORIES ä¸­
                print(f"æ–‡ç«  '{art.get('title', 'ç„¡æ¨™é¡Œ')}' å› é¡åˆ¥ '{standardized_category}' ä¸å±¬æ–¼ AI ç›¸é—œè€Œè¢«æ’é™¤ã€‚")

    # å°‡æ‰€æœ‰å·²åˆ†é¡ä¸¦ä¿ç•™çš„æ–‡ç« å¯«å…¥ä¸€å€‹ç¸½æª”æ¡ˆ
    with open(OUTPUT_ALL_FILE, "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)

    # å°‡æ–‡ç« æŒ‰ç…§åœ°å€å’Œæ¨™æº–åŒ–é¡åˆ¥åˆ†åˆ¥å¯«å…¥æª”æ¡ˆ
    for region, cats in grouped.items():
        for cat, items in cats.items(): # é€™è£¡çš„ 'cat' å·²ç¶“æ˜¯æ¨™æº–åŒ–å¾Œçš„é¡åˆ¥
            # åªæœ‰ç•¶è©²é¡åˆ¥ä¸‹æœ‰æ–‡ç« æ™‚æ‰å»ºç«‹æª”æ¡ˆ
            if items:
                # ç¢ºä¿æª”æ¡ˆåç¨±æ˜¯æœ‰æ•ˆçš„ï¼Œå°‡ç©ºæ ¼æ›¿æ›ç‚ºåº•ç·š
                filename = f"{region}_{cat.replace(' ', '_')}.json"
                path = os.path.join(CATEGORY_DIR, filename)
                with open(path, "w", encoding="utf-8") as f:
                    json.dump(items, f, ensure_ascii=False, indent=2)
    print(
        f"å·²å°‡ {len(results)} ç¯‡å·²åˆ†é¡çš„æ–‡ç« å¯«å…¥ {OUTPUT_ALL_FILE}"
    )
    print(f"âœ… æˆåŠŸåˆ†é¡ä¸¦ä¿ç•™çš„æ–‡ç« æ•¸é‡: {len(results)}")


if __name__ == "__main__":
    asyncio.run(main_async())